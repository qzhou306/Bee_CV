{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_YoloFastest_2_in_1_Qifang_complete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qzhou306/Bee_CV/blob/master/Test_YoloFastest_2_in_1_Qifang_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHBQcQzjD6HJ",
        "colab_type": "text"
      },
      "source": [
        "**Connect google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwp6NIrsZZFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "a0a0f965-aa6f-43ce-ca6f-e4307eec3175"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "# Check if NVIDIA GPU is enabled\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1831 sha256=9efae9e9ef99328b5563709629902a5204c6e6951e1b1c259d660bfe182adf69\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n",
            "Thu Sep 24 21:28:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e9ZW3sqMEPO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "ca2117c7-0e7a-4841-c355-ad4e8a8c0bee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "'02AUG KL ORDAMS 2人 票号 副本 (1).docx'\n",
            "'02AUG KL ORDAMS 2人 票号 副本.docx'\n",
            " 1_ALSWR.png\n",
            "'1 class files'\n",
            " backup\n",
            " bee\n",
            "'Colab Notebooks'\n",
            "'Cover Letter ADP.docx'\n",
            " cudnn-10.1-linux-x64-v8.0.2.39.tgz\n",
            " darknet\n",
            "'Gas Mileage.ipynb'\n",
            "'How to get started with Drive.pdf'\n",
            " HW1_ISYE8803.ipynb\n",
            " i-539a-XUE.pdf\n",
            " i-539-DENG.pdf\n",
            " Image_comparison.ipynb\n",
            " IMG_8227.jpg\n",
            "'interview tips.gdoc'\n",
            "'ISYE 6740 Final.ipynb'\n",
            "'ISYE 8803 HW3 Q1.ipynb'\n",
            "'Lawrence coding cert 1.jpg'\n",
            "'MIdterm 1 Q1 Qifang Zhou.ipynb'\n",
            "'My Drive'\n",
            "'New folder'\n",
            "'Qifang Zhou 2020_G.doc'\n",
            "'Qifang Zhou_Sep Data.docx'\n",
            "'Qifang Zhou_Sep Data.pdf'\n",
            "'Qifang Zhou_Sep.pdf'\n",
            " Qnote\n",
            " results.avi\n",
            " results.mp4\n",
            "'RPubs - Adaptive LASSO Examples.png'\n",
            " Sensata.gdoc\n",
            "'Sprayer Qnotes SAP w999.xlsx'\n",
            " TensorFlow-2.x-YOLOv3-master\n",
            "'Test Codes.ipynb'\n",
            " Traveller+public+health+declaration.pdf\n",
            " Untitled0.ipynb\n",
            "'week3 Car detection for Autonomous Driving .png'\n",
            "'Weld Qnote Classification.ipynb'\n",
            " yolov3\n",
            "'zgle-fork TensorFlow-2.x-YOLOv3: YOLOv3.png'\n",
            " Zhou_Qifang_HW7.ipynb\n",
            " 消毒车400W.zip\n",
            "time: 24.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7utW4in4azV",
        "colab_type": "text"
      },
      "source": [
        "**1) Clone, configure & compile Darknet**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e03U7Zi-qMr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "67145f4b-bcb8-44c2-d583-78d437d9dccb"
      },
      "source": [
        "# Clone\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 14309, done.\u001b[K\n",
            "remote: Total 14309 (delta 0), reused 0 (delta 0), pack-reused 14309\u001b[K\n",
            "Receiving objects: 100% (14309/14309), 12.86 MiB | 24.34 MiB/s, done.\n",
            "Resolving deltas: 100% (9766/9766), done.\n",
            "time: 2.42 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hzfEWSuONhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7283d878-824b-43f4-acb0-0b72e487a352"
      },
      "source": [
        "# Configure\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "# comment this line for other YOLOV3\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/darknet\n",
            "time: 441 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBBokOq5OOA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddc0a9f9-627c-4a18-b629-5796ce50fe91"
      },
      "source": [
        "# Compile\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir -p ./obj/\n",
            "mkdir -p backup\n",
            "chmod +x *.sh\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid draw_detections_cv_v3(void**, detection*, int, float, char**, image**, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:926:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Krgb\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                 float \u001b[01;35m\u001b[Krgb\u001b[m\u001b[K[3];\n",
            "                       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid draw_train_loss(char*, void**, int, float, float, int, int, float, int, char*, float, int, int, double)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1127:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "             \u001b[01;35m\u001b[Kif\u001b[m\u001b[K (iteration_old == 0)\n",
            "             \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1130:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "          \u001b[01;36m\u001b[Kif\u001b[m\u001b[K (iteration_old != 0){\n",
            "          \u001b[01;36m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid cv_draw_object(image, float*, int, int, int*, float*, int*, int, char**)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1424:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbuff\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         char \u001b[01;35m\u001b[Kbuff\u001b[m\u001b[K[100];\n",
            "              \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1400:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kit_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kit_tb_res\u001b[m\u001b[K = cv::createTrackbar(it_trackbar_name, window_name, &it_trackbar_value, 1000);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1404:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Klr_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Klr_tb_res\u001b[m\u001b[K = cv::createTrackbar(lr_trackbar_name, window_name, &lr_trackbar_value, 20);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1408:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kcl_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kcl_tb_res\u001b[m\u001b[K = cv::createTrackbar(cl_trackbar_name, window_name, &cl_trackbar_value, classes-1);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1411:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbo_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kbo_tb_res\u001b[m\u001b[K = cv::createTrackbar(bo_trackbar_name, window_name, boxonly, 1);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/http_stream.cpp -o obj/http_stream.o\n",
            "In file included from \u001b[01m\u001b[K./src/http_stream.cpp:580:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K./src/httplib.h:129:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K\"INVALID_SOCKET\" redefined\n",
            " #define INVALID_SOCKET (-1)\n",
            " \n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:73:0:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kthis is the location of the previous definition\n",
            " #define INVALID_SOCKET -1\n",
            " \n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool JSON_sender::write(const char*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:249:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = _write(client, outputbuf, outlen);\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool MJPG_sender::write(const cv::Mat&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:507:113:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%zu\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "                 sprintf(head, \"--mjpegstream\\r\\nContent-Type: image/jpeg\\r\\nContent-Length: %zu\\r\\n\\r\\n\", outlen\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid set_track_id(detection*, int, float, float, float, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:845:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "         for (int i = 0; \u001b[01;35m\u001b[Ki < v.size()\u001b[m\u001b[K; ++i) {\n",
            "                         \u001b[01;35m\u001b[K~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:853:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     for (int old_id = 0; \u001b[01;35m\u001b[Kold_id < old_dets.size()\u001b[m\u001b[K; ++old_id) {\n",
            "                          \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:873:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     for (int index = 0; \u001b[01;35m\u001b[Kindex < new_dets_num*old_dets.size()\u001b[m\u001b[K; ++index) {\n",
            "                         \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:908:28:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     if (\u001b[01;35m\u001b[Kold_dets_dq.size() > deque_size\u001b[m\u001b[K) old_dets_dq.pop_front();\n",
            "         \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gemm.c -o obj/gemm.o\n",
            "\u001b[01m\u001b[K./src/gemm.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kconvolution_2d\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gemm.c:2038:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     const int \u001b[01;35m\u001b[Kout_w\u001b[m\u001b[K = (w + 2 * pad - ksize) / stride + 1;    // output_width=input_width for stride=1 and pad=1\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gemm.c:2037:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     const int \u001b[01;35m\u001b[Kout_h\u001b[m\u001b[K = (h + 2 * pad - ksize) / stride + 1;    // output_height=input_height for stride=1 and pad=1\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/utils.c -o obj/utils.o\n",
            "\u001b[01m\u001b[K./src/utils.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcustom_hash\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/utils.c:1039:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest parentheses around assignment used as truth value [\u001b[01;35m\u001b[K-Wparentheses\u001b[m\u001b[K]\n",
            "     while (\u001b[01;35m\u001b[Kc\u001b[m\u001b[K = *str++)\n",
            "            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dark_cuda.c -o obj/dark_cuda.o\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcudnn_check_error_extended\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:224:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcudaError_t {aka enum cudaError}\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum <anonymous>\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "         if (status \u001b[01;35m\u001b[K!=\u001b[m\u001b[K CUDNN_STATUS_SUCCESS)\n",
            "                    \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpre_allocate_pinned_memory\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\"pre_allocate: size = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K MB, num_of_blocks = %Iu, block_size = %Iu MB \\n\",\n",
            "                                      \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                      \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "             \u001b[32m\u001b[Ksize / (1024*1024)\u001b[m\u001b[K, num_of_blocks, pinned_block_size / (1024 * 1024));\n",
            "             \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K          \n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\"pre_allocate: size = %Iu MB, num_of_blocks = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K, block_size = %Iu MB \\n\",\n",
            "                                                              \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                                              \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:82:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\"pre_allocate: size = %Iu MB, num_of_blocks = %Iu, block_size = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K MB \\n\",\n",
            "                                                                                \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                                                                \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:286:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "                 printf(\" Allocated \u001b[01;35m\u001b[K%d\u001b[m\u001b[K pinned block \\n\", pinned_block_size);\n",
            "                                    \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                    \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcuda_make_array_pinned_preallocated\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:307:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\"\\n Pinned block_id = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, filled = %f %% \\n\", pinned_block_id, filled);\n",
            "                                          \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                          \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:322:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\"Try to allocate new pinned memory, size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K MB \\n\", \u001b[32m\u001b[Ksize / (1024 * 1024)\u001b[m\u001b[K);\n",
            "                                                               \u001b[01;35m\u001b[K~^\u001b[m\u001b[K         \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "                                                               \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:328:63:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\"Try to allocate new pinned BLOCK, size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K MB \\n\", \u001b[32m\u001b[Ksize / (1024 * 1024)\u001b[m\u001b[K);\n",
            "                                                              \u001b[01;35m\u001b[K~^\u001b[m\u001b[K         \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "                                                              \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_convolutional_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:1337:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kt_intput_size\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                         size_t \u001b[01;35m\u001b[Kt_intput_size\u001b[m\u001b[K = binary_transpose_align_input(k, n, state.workspace, &l.t_bit_input, ldb_align, l.bit_align);\n",
            "                                \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/list.c -o obj/list.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/image.c -o obj/image.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/activations.c -o obj/activations.o\n",
            "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kactivate\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KRELU6\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KHARD_MISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX_MAXVAL\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kgradient\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KHARD_MISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/im2col.c -o obj/im2col.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/col2im.c -o obj/col2im.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/blas.c -o obj/blas.o\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbackward_shortcut_multilayer_cpu\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:207:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_index\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int \u001b[01;35m\u001b[Kout_index\u001b[m\u001b[K = id;\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfind_sim\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:597:59:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_sim(): sim isn't found: i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, j = %d, z = %d \\n\", i, j, z);\n",
            "                                                          \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                          \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:597:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_sim(): sim isn't found: i = %d, j = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, z = %d \\n\", i, j, z);\n",
            "                                                                  \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                  \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:597:75:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_sim(): sim isn't found: i = %d, j = %d, z = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, j, z);\n",
            "                                                                          \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                          \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfind_P_constrastive\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:611:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_P_constrastive(): P isn't found: i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, j = %d, z = %d \\n\", i, j, z);\n",
            "                                                                   \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                   \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:611:76:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_P_constrastive(): P isn't found: i = %d, j = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, z = %d \\n\", i, j, z);\n",
            "                                                                           \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                           \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:611:84:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_P_constrastive(): P isn't found: i = %d, j = %d, z = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, j, z);\n",
            "                                                                                   \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                                   \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KP_constrastive_f\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:651:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, l = %d \\n\", i, l);\n",
            "                                                                              \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                              \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:651:87:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = %d, l = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, l);\n",
            "                                                                                      \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                                      \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KP_constrastive\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:785:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, l = %d \\n\", i, l);\n",
            "                                                                              \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                              \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:785:87:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = %d, l = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, l);\n",
            "                                                                                      \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                                      \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/crop_layer.c -o obj/crop_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dropout_layer.c -o obj/dropout_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/maxpool_layer.c -o obj/maxpool_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/softmax_layer.c -o obj/softmax_layer.o\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_contrastive_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:203:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 9 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "     fprintf(stderr, \"contrastive %4d x%4d x%4d x emb_size %4d x batch: %4d  classes = %4d, step = \u001b[01;35m\u001b[K%4d\u001b[m\u001b[K \\n\", w, h, l.n, l.embedding_size, batch, l.classes, step);\n",
            "                                                                                                   \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                                                                                   \u001b[32m\u001b[K%4ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_contrastive_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:244:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kmax_truth\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kmax_truth\u001b[m\u001b[K = 0;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:423:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\" Error: too large number of bboxes: contr_size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K > max_contr_size  = %d \\n\", contr_size, max_contr_size);\n",
            "                                                                      \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                      \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/data.c -o obj/data.o\n",
            "\u001b[01m\u001b[K./src/data.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kload_data_detection\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/data.c:1297:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kx\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int k, \u001b[01;35m\u001b[Kx\u001b[m\u001b[K, y;\n",
            "                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/data.c:1090:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kr_scale\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "     float r1 = 0, r2 = 0, r3 = 0, r4 = 0, \u001b[01;35m\u001b[Kr_scale\u001b[m\u001b[K = 0;\n",
            "                                           \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/matrix.c -o obj/matrix.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/network.c -o obj/network.o\n",
            "\u001b[01m\u001b[K./src/network.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_network\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/network.c:615:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Knet->input_pinned_cpu, size * sizeof(float), cudaHostRegisterMapped))\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/network.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/connected_layer.c -o obj/connected_layer.o\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_connected_layer_gpu\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:346:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kone\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Kone\u001b[m\u001b[K = 1;    // alpha[0], beta[0]\n",
            "           \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:344:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kc\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float * \u001b[01;35m\u001b[Kc\u001b[m\u001b[K = l.output_gpu;\n",
            "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:343:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kb\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float * \u001b[01;35m\u001b[Kb\u001b[m\u001b[K = l.weights_gpu;\n",
            "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:342:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ka\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float * \u001b[01;35m\u001b[Ka\u001b[m\u001b[K = state.input;\n",
            "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:341:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = l.outputs;\n",
            "         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:340:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kk\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kk\u001b[m\u001b[K = l.inputs;\n",
            "         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:339:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Km\u001b[m\u001b[K = l.batch;\n",
            "         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/cost_layer.c -o obj/cost_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/parser.c -o obj/parser.o\n",
            "\u001b[01m\u001b[K./src/parser.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kparse_network_cfg_custom\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/parser.c:1669:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Knet.input_pinned_cpu, size * sizeof(float), cudaHostRegisterMapped)) net.input_pinned_cpu_flag = 1;\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activation_layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/parser.c:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/parser.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kget_classes_multipliers\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/parser.c:428:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kargument 1 range [18446744071562067968, 18446744073709551615] exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K-Walloc-size-larger-than=\u001b[m\u001b[K]\n",
            "         \u001b[01;35m\u001b[Kclasses_multipliers = (float *)calloc(classes_counters, sizeof(float))\u001b[m\u001b[K;\n",
            "         \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K./src/parser.c:3:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/stdlib.h:541:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin a call to allocation function ‘\u001b[01m\u001b[Kcalloc\u001b[m\u001b[K’ declared here\n",
            " extern void *\u001b[01;36m\u001b[Kcalloc\u001b[m\u001b[K (size_t __nmemb, size_t __size)\n",
            "              \u001b[01;36m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/option_list.c -o obj/option_list.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/darknet.c -o obj/darknet.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/detection_layer.c -o obj/detection_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/captcha.c -o obj/captcha.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/route_layer.c -o obj/route_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/writing.c -o obj/writing.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/box.c -o obj/box.o\n",
            "\u001b[01m\u001b[K./src/box.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbox_iou_kind\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/box.c:154:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMSE\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(iou_kind) {\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/box.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdiounms_sort\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/box.c:898:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbeta_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kbeta_prob\u001b[m\u001b[K = pow(dets[j].prob[k], 2) / sum_prob;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/box.c:897:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kalpha_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kalpha_prob\u001b[m\u001b[K = pow(dets[i].prob[k], 2) / sum_prob;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/nightmare.c -o obj/nightmare.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/normalization_layer.c -o obj/normalization_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/avgpool_layer.c -o obj/avgpool_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/coco.c -o obj/coco.o\n",
            "\u001b[01m\u001b[K./src/coco.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_coco_recall\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/coco.c:248:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbase\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     char *\u001b[01;35m\u001b[Kbase\u001b[m\u001b[K = \"results/comp4_det_test_\";\n",
            "           \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dice.c -o obj/dice.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/yolo.c -o obj/yolo.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/detector.c -o obj/detector.o\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kprint_cocos\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:478:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat not a string literal and no format arguments [\u001b[01;35m\u001b[K-Wformat-security\u001b[m\u001b[K]\n",
            "                 fprintf(fp, \u001b[01;35m\u001b[Kbuff\u001b[m\u001b[K);\n",
            "                             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Keliminate_bdd\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:571:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kstatement with no effect [\u001b[01;35m\u001b[K-Wunused-value\u001b[m\u001b[K]\n",
            "                     \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (k; buf[k + n] != '\\0'; k++)\n",
            "                     \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:692:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd2\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kmkd2\u001b[m\u001b[K = make_directory(buff2, 0777);\n",
            "             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:690:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kmkd\u001b[m\u001b[K = make_directory(buff, 0777);\n",
            "             \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector_map\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:1323:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_recall\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kclass_recall\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)(truth_classes_count[i] - tp_for_thresh_per_class[i]));\n",
            "               \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:1322:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_precision\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kclass_precision\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)fp_for_thresh_per_class[i]);\n",
            "               \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdraw_object\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:1857:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kinv_loss\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "             float \u001b[01;35m\u001b[Kinv_loss\u001b[m\u001b[K = 1.0 / max_val_cmp(0.01, avg_loss);\n",
            "                   \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/layer.c -o obj/layer.o\n",
            "\u001b[01m\u001b[K./src/layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfree_layer_custom\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/layer.c:205:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest parentheses around ‘\u001b[01m\u001b[K&&\u001b[m\u001b[K’ within ‘\u001b[01m\u001b[K||\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wparentheses\u001b[m\u001b[K]\n",
            "     if (l.delta_gpu && (l.optimized_memory < 1 || \u001b[01;35m\u001b[Kl.keep_delta_gpu && l.optimized_memory < 3\u001b[m\u001b[K)) cuda_free(l.delta_gpu), l.delta_gpu = NULL;\n",
            "                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/compare.c -o obj/compare.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/classifier.c -o obj/classifier.o\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:146:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kcount\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kcount\u001b[m\u001b[K = 0;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpredict_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:855:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktime\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     clock_t \u001b[01;35m\u001b[Ktime\u001b[m\u001b[K;\n",
            "             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdemo_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:1287:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktval_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         struct timeval tval_before, tval_after, \u001b[01;35m\u001b[Ktval_result\u001b[m\u001b[K;\n",
            "                                                 \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/classifier.c:1287:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktval_after\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         struct timeval tval_before, \u001b[01;35m\u001b[Ktval_after\u001b[m\u001b[K, tval_result;\n",
            "                                     \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/local_layer.c -o obj/local_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/swag.c -o obj/swag.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/shortcut_layer.c -o obj/shortcut_layer.o\n",
            "\u001b[01m\u001b[K./src/shortcut_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_shortcut_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/shortcut_layer.c:55:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kscale\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kscale\u001b[m\u001b[K = sqrt(2. / l.nweights);\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/activation_layer.c -o obj/activation_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn_layer.c -o obj/rnn_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gru_layer.c -o obj/gru_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn.c -o obj/rnn.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn_vid.c -o obj/rnn_vid.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/crnn_layer.c -o obj/crnn_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/demo.c -o obj/demo.o\n",
            "\u001b[01m\u001b[K./src/demo.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdetect_in_thread\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/demo.c:100:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kprediction\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float *\u001b[01;35m\u001b[Kprediction\u001b[m\u001b[K = network_predict(net, X);\n",
            "                \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/demo.c:98:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kl\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         layer \u001b[01;35m\u001b[Kl\u001b[m\u001b[K = net.layers[net.n - 1];\n",
            "               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/tag.c -o obj/tag.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/cifar.c -o obj/cifar.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/go.c -o obj/go.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/batchnorm_layer.c -o obj/batchnorm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/art.c -o obj/art.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/region_layer.c -o obj/region_layer.o\n",
            "\u001b[01m\u001b[K./src/region_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_region_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/region_layer.c:59:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kold_h\u001b[m\u001b[K = l->h;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/region_layer.c:58:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kold_w\u001b[m\u001b[K = l->w;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/reorg_layer.c -o obj/reorg_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/reorg_old_layer.c -o obj/reorg_old_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/super.c -o obj/super.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/voxel.c -o obj/voxel.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/tree.c -o obj/tree.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/yolo_layer.c -o obj/yolo_layer.o\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:68:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.output, batch*l.outputs*sizeof(float), cudaHostRegisterMapped)) l.output_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:75:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.delta, batch*l.outputs*sizeof(float), cudaHostRegisterMapped)) l.delta_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:106:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->output, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:115:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->delta, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:394:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kbest_match_t\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                     int \u001b[01;35m\u001b[Kbest_match_t\u001b[m\u001b[K = 0;\n",
            "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gaussian_yolo_layer.c -o obj/gaussian_yolo_layer.o\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_gaussian_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:71:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.output, batch*l.outputs * sizeof(float), cudaHostRegisterMapped)) l.output_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:78:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.delta, batch*l.outputs * sizeof(float), cudaHostRegisterMapped)) l.delta_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_gaussian_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:110:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->output, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:119:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->delta, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/upsample_layer.c -o obj/upsample_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/lstm_layer.c -o obj/lstm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/conv_lstm_layer.c -o obj/conv_lstm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/scale_channels_layer.c -o obj/scale_channels_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/sam_layer.c -o obj/sam_layer.o\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/convolutional_kernels.cu -o obj/convolutional_kernels.o\n",
            "\u001b[01m\u001b[K./src/convolutional_kernels.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid backward_convolutional_layer_gpu(convolutional_layer, network_state)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_kernels.cu:853:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[K            if (*state.net.max_output16_size < l.\u001b[m\u001b[Knweights) {\n",
            "                 \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/activation_kernels.cu -o obj/activation_kernels.o\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/im2col_kernels.cu -o obj/im2col_kernels.o\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/col2im_kernels.cu -o obj/col2im_kernels.o\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/blas_kernels.cu -o obj/blas_kernels.o\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[K./src/blas_kernels.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid backward_shortcut_multilayer_gpu(int, int, int, int*, float**, float*, float*, float*, float*, int, float*, float**, WEIGHTS_NORMALIZATION_T)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas_kernels.cu:1130:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kstep\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kint \u001b[m\u001b[Kstep = 0;\n",
            "     \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/crop_layer_kernels.cu -o obj/crop_layer_kernels.o\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/dropout_layer_kernels.cu -o obj/dropout_layer_kernels.o\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/maxpool_layer_kernels.cu -o obj/maxpool_layer_kernels.o\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/network_kernels.cu -o obj/network_kernels.o\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[K./src/network_kernels.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfloat train_network_datum_gpu(network, float*, float*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/network_kernels.cu:364:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kl\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[K \u001b[m\u001b[K layer l = net.layers[net.n - 1];\n",
            "       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "nvcc -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/avgpool_layer_kernels.cu -o obj/avgpool_layer_kernels.o\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF obj/image_opencv.o obj/http_stream.o obj/gemm.o obj/utils.o obj/dark_cuda.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/darknet.o obj/detection_layer.o obj/captcha.o obj/route_layer.o obj/writing.o obj/box.o obj/nightmare.o obj/normalization_layer.o obj/avgpool_layer.o obj/coco.o obj/dice.o obj/yolo.o obj/detector.o obj/layer.o obj/compare.o obj/classifier.o obj/local_layer.o obj/swag.o obj/shortcut_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/rnn.o obj/rnn_vid.o obj/crnn_layer.o obj/demo.o obj/tag.o obj/cifar.o obj/go.o obj/batchnorm_layer.o obj/art.o obj/region_layer.o obj/reorg_layer.o obj/reorg_old_layer.o obj/super.o obj/voxel.o obj/tree.o obj/yolo_layer.o obj/gaussian_yolo_layer.o obj/upsample_layer.o obj/lstm_layer.o obj/conv_lstm_layer.o obj/scale_channels_layer.o obj/sam_layer.o obj/convolutional_kernels.o obj/activation_kernels.o obj/im2col_kernels.o obj/col2im_kernels.o obj/blas_kernels.o obj/crop_layer_kernels.o obj/dropout_layer_kernels.o obj/maxpool_layer_kernels.o obj/network_kernels.o obj/avgpool_layer_kernels.o -o darknet -lm -pthread `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv` -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand -L/usr/local/cudnn/lib64 -lcudnn -lstdc++\n",
            "time: 1min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAOLtA_qI9vF",
        "colab_type": "text"
      },
      "source": [
        "**2) Configure yolov3.cfg file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-RpscgU853t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2d6d13a7-5bde-4f3b-aefc-f323d47e5a4b"
      },
      "source": [
        "# Make a copy of yolo-fastest.cfg\n",
        "!cp /mydrive/yolov3/yolo-fastest.cfg cfg/yolo-fastest_training.cfg "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 411 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZgVQRop_vwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1340c917-8c8f-4082-84b4-817cba89f9f6"
      },
      "source": [
        "# Change lines in yolov3.cfg file\n",
        "'''\n",
        "!sed -i 's/batch=1/batch=64/' cfg/yolo-fastest_training.cfg\n",
        "!sed -i 's/subdivisions=1/subdivisions=16/' cfg/yolo-fastest_training.cfg\n",
        "!sed -i 's/max_batches = 500200/max_batches = 4000/' cfg/yolo-fastest_training.cfg\n",
        "!sed -i '610 s@classes=80@classes=2@' cfg/yolo-fastest_training.cfg\n",
        "!sed -i '696 s@classes=80@classes=2@' cfg/yolo-fastest_training.cfg\n",
        "!sed -i '783 s@classes=80@classes=2@' cfg/yolo-fastest_training.cfg\n",
        "!sed -i '603 s@filters=255@filters=21@' cfg/yolo-fastest_training.cfg\n",
        "!sed -i '689 s@filters=255@filters=21@' cfg/yolo-fastest_training.cfg\n",
        "!sed -i '776 s@filters=255@filters=21@' cfg/yolo-fastest_training.cfg\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!sed -i 's/batch=1/batch=64/' cfg/yolo-fastest_training.cfg\\n!sed -i 's/subdivisions=1/subdivisions=16/' cfg/yolo-fastest_training.cfg\\n!sed -i 's/max_batches = 500200/max_batches = 4000/' cfg/yolo-fastest_training.cfg\\n!sed -i '610 s@classes=80@classes=2@' cfg/yolo-fastest_training.cfg\\n!sed -i '696 s@classes=80@classes=2@' cfg/yolo-fastest_training.cfg\\n!sed -i '783 s@classes=80@classes=2@' cfg/yolo-fastest_training.cfg\\n!sed -i '603 s@filters=255@filters=21@' cfg/yolo-fastest_training.cfg\\n!sed -i '689 s@filters=255@filters=21@' cfg/yolo-fastest_training.cfg\\n!sed -i '776 s@filters=255@filters=21@' cfg/yolo-fastest_training.cfg\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.87 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88p9BIjkPTRv",
        "colab_type": "text"
      },
      "source": [
        "**3) Create .names and .data files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AIBw_psIclz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f5c57ba3-c89d-46ec-a682-d1c51077cdd2"
      },
      "source": [
        "# step 1 - Bee\n",
        "!echo -e 'Bee' > data/obj.names\n",
        "!echo -e 'classes= 1\\ntrain  = data/train.txt\\nvalid  = data/test.txt\\nnames = data/obj.names\\nbackup = /mydrive/yolov3' > data/obj.data\n",
        "\n",
        "# step 2 - Pollen\n",
        "!echo -e 'Pollen' > data/objPollen.names\n",
        "!echo -e 'classes= 1\\ntrain  = data/train.txt\\nvalid  = data/test.txt\\nnames = data/objPollen.names\\nbackup = /mydrive/yolov3' > data/objPollen.data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 433 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqFFqbUJMtN-",
        "colab_type": "text"
      },
      "source": [
        "**4) Save yolov3_training.cfg and obj.names files in Google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67o96gV7L0Uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3a1660f0-caae-4cc2-9dbf-5bba308cf6b3"
      },
      "source": [
        "#!cp cfg/yolov3_training.cfg /mydrive/yolov3/yolov3_testing.cfg\n",
        "!cp data/obj.names /mydrive/yolov3/classes.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 310 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RbVKJjoncW2",
        "colab_type": "text"
      },
      "source": [
        "**5) Create a folder and unzip image dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZlkzFMW7I_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccc6c54a-8b44-4606-cad5-0e4b515f802d"
      },
      "source": [
        "!rm -rf data/obj\n",
        "!mkdir -p data/obj\n",
        "!unzip /mydrive/yolov3/images_bee.zip -d data/obj"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /mydrive/yolov3/images_bee.zip\n",
            "   creating: data/obj/b_1classes_derived/\n",
            "  inflating: data/obj/b_1classes_derived/0003.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0003.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0013.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0013.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0023.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0023.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0033.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0033.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0043.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0043.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0053.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0053.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0063.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0063.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0073.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0073.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0083.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0083.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0093.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0093.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0103.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0103.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0113.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0113.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0123.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0123.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0133.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0133.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0143.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0143.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0153.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0153.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0163.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0163.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0173.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0173.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0183.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0183.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0193.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0193.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0203.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0203.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0213.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0213.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0223.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0223.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0233.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0233.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0243.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0243.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0253.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0253.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0263.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0263.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0273.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0273.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0283.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0283.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0293.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0293.txt  \n",
            "  inflating: data/obj/b_1classes_derived/0303.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/0303.txt  \n",
            " extracting: data/obj/b_1classes_derived/classes.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00001.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00001.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00002.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00002.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00003.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00003.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00004.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00004.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00005.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00005.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00006.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00006.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00007.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00007.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00008.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00008.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00009.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00009.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00010.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00010.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00011.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00011.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00012.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00012.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00013.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00013.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00014.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00014.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00015.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00015.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00016.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00016.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00017.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00017.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00018.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00018.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00019.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00019.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00020.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00020.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00021.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00021.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00022.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00022.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00023.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00023.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00024.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00024.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00025.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00025.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00026.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00026.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00027.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00027.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00028.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00028.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00029.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00029.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00030.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00030.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00031.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00031.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00032.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00032.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00033.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00033.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00034.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00034.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00035.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00035.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00036.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00036.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00037.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00037.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00038.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00038.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00039.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00039.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00040.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00040.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00041.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00041.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00055.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00055.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00056.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00056.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00057.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00057.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00058.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00058.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00059.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00059.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00061.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00061.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00078.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00078.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00081.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00081.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00082.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00082.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00083.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00083.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00084.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00084.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00091.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00091.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00092.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00092.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00093.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00093.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00094.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00094.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00095.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00095.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00096.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00096.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00097.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00097.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00098.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00098.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00101.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00101.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00102.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00102.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00103.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00103.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00104.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00104.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00105.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00105.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00106.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00106.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00115.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00115.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00116.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00116.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00124.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00124.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00127.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00127.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00129.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00129.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00132.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00132.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00135.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00135.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00141.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00141.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00149.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00149.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00155.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00155.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00156.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00156.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00171.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00171.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00172.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00172.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00173.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00173.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00199.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00199.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00214.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00214.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00215.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00215.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00216.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00216.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00217.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00217.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00218.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00218.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00242.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00242.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00243.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00243.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00252.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00252.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00253.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00253.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00254.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00254.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00255.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00255.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00256.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00256.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00258.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00258.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00269.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00269.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00274.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00274.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00275.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00275.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00303.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00303.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00304.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00304.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00305.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00305.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00329.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00329.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00331.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00331.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00334.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00334.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00335.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00335.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00336.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00336.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00350.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00350.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00351.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00351.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00353.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00353.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00358.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00358.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00359.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00359.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00376.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00376.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00377.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00377.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00378.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00378.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00379.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00379.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00382.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00382.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00429.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00429.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00431.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00431.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00438.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00438.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00439.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00439.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00452.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00452.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00453.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00453.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00454.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00454.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00462.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00462.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00463.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00463.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00464.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00464.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00465.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00465.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00466.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00466.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00467.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00467.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00468.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00468.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00469.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00469.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00470.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00470.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00471.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00471.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00472.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00472.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00473.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00473.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00474.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00474.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00477.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00477.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00478.jpg  \n",
            " extracting: data/obj/b_1classes_derived/img00478.txt  \n",
            "  inflating: data/obj/b_1classes_derived/img00479.jpg  \n",
            "  inflating: data/obj/b_1classes_derived/img00479.txt  \n",
            "time: 1.03 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogBdNwRaZ50U",
        "colab_type": "text"
      },
      "source": [
        "**6) Create train.txt file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGUyXxeYX0IP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8c459646-e764-44f9-9baa-a6147f0ac896"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "\n",
        "img_list = glob.glob(\"data/obj/b_1classes_derived/*.jpg\")\n",
        "random.shuffle(img_list)\n",
        "with open(\"data/train.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(img_list[:int(len(img_list)*0.7)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.52 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sZT35JrOTVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c56cec21-f51b-492c-82e5-434a271d1b39"
      },
      "source": [
        "with open(\"data/test.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(img_list[int(len(img_list)*0.7):]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.48 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084L-LLPqxQe",
        "colab_type": "text"
      },
      "source": [
        "**7) Download pre-trained weights for the convolutional layers file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhb5nZvsQ_96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "547f3ec7-59d3-4d2f-958c-a95a635ace37"
      },
      "source": [
        "#!wget https://pjreddie.com/media/files/darknet53.conv.74\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.15 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9AhwGoid6jC",
        "colab_type": "text"
      },
      "source": [
        "Generate a pre-trained model for the initialization of the model backbone\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlJws6s0g88D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3d83b6fe-4942-4494-9223-f56b5ebff3d8"
      },
      "source": [
        "# # Make a copy of yolo-fastest.weights\n",
        "#!cp /mydrive/yolov3/yolo-fastest.weights backup/yolo-fastest.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 441 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OFPYUGZd7dX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3c6ee58e-8b3b-4af5-8727-65bed647e6d0"
      },
      "source": [
        "#!./darknet partial cfg/yolo-fastest_training.cfg backup/yolo-fastest.weights yolo-fastest.conv.109 109"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.37 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeSiuLrXoAjc",
        "colab_type": "text"
      },
      "source": [
        "**8) Start training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3_g3jclUzMm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5f1121d1-e658-4411-b9fa-277edeec3157"
      },
      "source": [
        "#!./darknet detector train data/obj.data cfg/yolov3_training.cfg darknet53.conv.74 -dont_show\n",
        "# Uncomment below and comment above to re-start your training from last saved weights\n",
        "#!./darknet detector train data/obj.data cfg/yolo-fastest_training.cfg yolo-fastest.conv.109  -dont_show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 853 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esMRinRtPXj7",
        "colab_type": "text"
      },
      "source": [
        "Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jid1hWiSPm9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b981e09b-b40f-485a-ab09-12b2f573477a"
      },
      "source": [
        "# derive the paths to the YOLO weights and model configuration\n",
        "\n",
        "objPath=\"data/obj.data\" # for step 1 bee\n",
        "objPollenPath=\"data/objPollen.data\" # for step 2 pollen\n",
        "beeweightsPath = \"/mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights\"  # for step 1 bee\n",
        "pollenweightsPath = \"/mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights\"  # for step 2 pollen\n",
        "configPath = \"/mydrive/yolov3/yolo-fastest.cfg\"  # common config file\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.22 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy3gRNK2Pv6O",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs7KwYEA5Osj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define helper functions\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "%matplotlib inline\n",
        "\n",
        "def imShow(path):\n",
        "\n",
        "\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# use this to upload files\n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# use this to download a file  \n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efs0-dey4fC7",
        "colab_type": "text"
      },
      "source": [
        "Convert video to image: save all images vs. save it in a 3D array and get overwritten every frame? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMYEaUlHwY2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d2e7cb56-0296-4846-b8eb-e0a9f13589d2"
      },
      "source": [
        "# capture images from video and save all images on google drive - slow\n",
        "'''\n",
        "videoPath = \"/mydrive/yolov3/Cheng_1_trim.mp4\"\n",
        "cap = cv2.VideoCapture(videoPath)\n",
        "img_id = 1\n",
        "\n",
        "while True:\n",
        "    _,frame = cap.read()\n",
        "    filename = 'testimg'+str(img_id)+'.jpg'\n",
        "    img_id +=1\n",
        "    cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvideoPath = \"/mydrive/yolov3/Cheng_1_trim.mp4\"\\ncap = cv2.VideoCapture(videoPath)\\nimg_id = 1\\n\\nwhile True:\\n    _,frame = cap.read()\\n    filename = \\'testimg\\'+str(img_id)+\\'.jpg\\'\\n    img_id +=1\\n    cv2.imwrite(filename, frame)\\ncap.release()\\ncv2.destroyAllWindows()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.11 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1EEWfmZStgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3e922c38-9e29-4d13-fa18-b2d3fd32fbc7"
      },
      "source": [
        "# This stops 'Run all' at this cell by causing an error\n",
        "#assert False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 583 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXY40vGR4xgV",
        "colab_type": "text"
      },
      "source": [
        "Run YOLO big image model to generate json files for bounding boxes and probability "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeZu-RC3aOzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7e61225a-6184-47b9-da2c-f829a7507473"
      },
      "source": [
        "def json_extract(obj, key):\n",
        "    \"\"\"Recursively fetch values from nested JSON.\"\"\"\n",
        "    arr = []\n",
        "\n",
        "    def extract(obj, arr, key):\n",
        "        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n",
        "        if isinstance(obj, dict):\n",
        "            for k, v in obj.items():\n",
        "                if isinstance(v, (dict, list)):\n",
        "                    extract(v, arr, key)\n",
        "                elif k == key:\n",
        "                    arr.append(v)\n",
        "        elif isinstance(obj, list):\n",
        "            for item in obj:\n",
        "                extract(item, arr, key)\n",
        "        return arr\n",
        "\n",
        "    values = extract(obj, arr, key)\n",
        "    return values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 20.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNs8xW2ppeuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "13502563-ffd3-4c96-d4a4-6e49fdb7874f"
      },
      "source": [
        "# crop images(3D array) to bee chips\n",
        "def crop_image(imgName, imgData, bee_arr):\n",
        "  bee_id = 1\n",
        "  imgWidth = imgData.shape[1]\n",
        "  imgHeight = imgData.shape[0]\n",
        "  for i in bee_arr:\n",
        "    filename = '/mydrive/yolov3/2_in_1_img/bee_chips/' + imgName +'_bee'+str(bee_id)+'.jpg'\n",
        "    bee_id +=1\n",
        "    w = int(i[2]*imgWidth*1.2)\n",
        "    h = int(i[3]*imgHeight*1.2)\n",
        "    x = int(i[0]*imgWidth)\n",
        "    y = int(i[1]*imgHeight) \n",
        "    #print('x', x, 'y', y, 'w', w, 'h', h)\n",
        "    #bbox_color_bgr_sacs=(255,0,255)\n",
        "    #line_thickness=2\n",
        "    bee_img = imgData[max(0, int(y-h/2)) : min(imgHeight, int(y+h/2)), max(0, int(x-w/2)) : min(imgWidth, int(x+w/2)), :]\n",
        "    #cv2.rectangle(imgData, (x,y), (x+w, y+h), bbox_color_bgr_sacs, line_thickness)\n",
        "    plt.imsave(filename, bee_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 46.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SYDLyW76v1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14f981e0-25fe-4e24-a168-961e1773d370"
      },
      "source": [
        "# outpout json file for single image\n",
        "# !./darknet detector test <path to .data file> <path to config> <path to weights> <path to image>\n",
        "img_list = glob.glob(\"/mydrive/yolov3/2_in_1_img/*.jpg\")\n",
        "\n",
        "for img in img_list:\n",
        "  ts = time.time()\n",
        "  print(ts)\n",
        "  #img = \"/mydrive/yolov3/2_in_1_img/testimg1.jpg\"\n",
        "  imgName = img[27:-4]\n",
        "  imgData = plt.imread(img)\n",
        "  !./darknet detector test $objPath $configPath $beeweightsPath $img -ext_output -dont_show -out result_bee.json\n",
        "  ts = time.time()\n",
        "  print(ts)\n",
        "  # Open the json file\n",
        "  with open('/content/darknet/result_bee.json') as f:\n",
        "    data = json.load(f)\n",
        "  data = data[0]\n",
        "  # Find every instance of `name` in a Python dictionary.\n",
        "  center_x = json_extract(data, 'center_x')\n",
        "  center_y = json_extract(data, 'center_y')\n",
        "  width = json_extract(data, 'width')\n",
        "  height = json_extract(data, 'height')\n",
        "  confidence = json_extract(data, 'confidence')\n",
        "  bee_arr = np.column_stack([center_x, center_y, width, height, confidence])\n",
        "  # crop image and generate individual bee chip images for step 2\n",
        "  crop_image(imgName, imgData, bee_arr)\n",
        "  ts = time.time()\n",
        "  print(ts)\n",
        "  # create path for chip images to load into step 2, probably can be more concise \n",
        "  img_list=glob.glob(\"/mydrive/yolov3/2_in_1_img/bee_chips/*.jpg\")\n",
        "  with open(\"data/pollen.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(img_list))\n",
        "  val_img_list=\"data/pollen.txt\"\n",
        "  !cat $val_img_list | wc -l\n",
        "  #Multiple Images at Once - Step 2 Pollen detection from all individual chip bee images\n",
        "  !./darknet detector test $objPollenPath $configPath $pollenweightsPath -ext_output -dont_show -out result_pollen.json <$val_img_list> result_pollen.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600983009.0465918\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg2.jpg: Predicted in 3.798000 milli-seconds.\n",
            "Bee: 81%\t(left_x:  370   top_y:  504   width:  136   height:  110)\n",
            "Bee: 26%\t(left_x:  422   top_y:  526   width:  140   height:  100)\n",
            "Bee: 82%\t(left_x:  697   top_y:  376   width:   94   height:  100)\n",
            "Bee: 90%\t(left_x: 1193   top_y:  210   width:   99   height:   99)\n",
            "1600983017.9696286\n",
            "1600983018.8981292\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983029.9564672\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg10.jpg: Predicted in 3.883000 milli-seconds.\n",
            "Bee: 93%\t(left_x:  204   top_y:  554   width:   99   height:  130)\n",
            "Bee: 78%\t(left_x:  563   top_y:  561   width:  103   height:  137)\n",
            "Bee: 61%\t(left_x: 1121   top_y:  519   width:  109   height:  123)\n",
            "Bee: 36%\t(left_x: 1452   top_y:  785   width:   91   height:   91)\n",
            "1600983032.6508229\n",
            "1600983032.6712446\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983035.4065468\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg7.jpg: Predicted in 3.758000 milli-seconds.\n",
            "Bee: 85%\t(left_x:  214   top_y:  539   width:  114   height:  120)\n",
            "Bee: 83%\t(left_x:  488   top_y:  528   width:  113   height:  148)\n",
            "Bee: 45%\t(left_x:  537   top_y:  507   width:   98   height:  114)\n",
            "Bee: 79%\t(left_x: 1090   top_y:  355   width:  105   height:  121)\n",
            "1600983038.18543\n",
            "1600983038.3119326\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983041.0434585\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg6.jpg: Predicted in 3.887000 milli-seconds.\n",
            "Bee: 77%\t(left_x:  205   top_y:  527   width:  127   height:  141)\n",
            "Bee: 81%\t(left_x:  468   top_y:  538   width:  109   height:  134)\n",
            "Bee: 27%\t(left_x:  585   top_y:  490   width:   87   height:   88)\n",
            "Bee: 70%\t(left_x: 1088   top_y:  293   width:  110   height:  137)\n",
            "1600983043.7078903\n",
            "1600983043.7290368\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983046.4605985\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg3.jpg: Predicted in 3.815000 milli-seconds.\n",
            "Bee: 84%\t(left_x:  304   top_y:  506   width:  124   height:  115)\n",
            "Bee: 44%\t(left_x:  379   top_y:  514   width:  119   height:  101)\n",
            "Bee: 34%\t(left_x:  463   top_y:  529   width:  114   height:   88)\n",
            "Bee: 92%\t(left_x:  663   top_y:  406   width:  101   height:   98)\n",
            "Bee: 95%\t(left_x: 1163   top_y:  242   width:   94   height:   73)\n",
            "1600983049.3324184\n",
            "1600983049.3586493\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983052.0923567\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg5.jpg: Predicted in 3.779000 milli-seconds.\n",
            "Bee: 83%\t(left_x:  259   top_y:  515   width:  110   height:  123)\n",
            "Bee: 39%\t(left_x:  466   top_y:  568   width:  105   height:   72)\n",
            "Bee: 45%\t(left_x:  616   top_y:  470   width:   96   height:   86)\n",
            "Bee: 75%\t(left_x: 1106   top_y:  241   width:  107   height:  180)\n",
            "1600983054.8875515\n",
            "1600983054.9288616\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983057.6637597\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg4.jpg: Predicted in 3.868000 milli-seconds.\n",
            "Bee: 89%\t(left_x:  288   top_y:  516   width:  120   height:  108)\n",
            "Bee: 72%\t(left_x:  647   top_y:  441   width:   89   height:  103)\n",
            "Bee: 91%\t(left_x: 1121   top_y:  259   width:   97   height:   91)\n",
            "1600983060.474681\n",
            "1600983060.4906864\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983063.2237856\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg8.jpg: Predicted in 3.733000 milli-seconds.\n",
            "Bee: 82%\t(left_x:  210   top_y:  532   width:  112   height:  134)\n",
            "Bee: 61%\t(left_x:  512   top_y:  540   width:  103   height:  124)\n",
            "Bee: 40%\t(left_x:  524   top_y:  508   width:  133   height:  191)\n",
            "Bee: 72%\t(left_x: 1088   top_y:  419   width:  109   height:   99)\n",
            "Bee: 26%\t(left_x: 1451   top_y:  790   width:   89   height:   85)\n",
            "1600983065.8905563\n",
            "1600983065.920315\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983068.6522603\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg9.jpg: Predicted in 3.768000 milli-seconds.\n",
            "Bee: 84%\t(left_x:  220   top_y:  527   width:   95   height:  155)\n",
            "Bee: 87%\t(left_x:  526   top_y:  544   width:  131   height:  133)\n",
            "Bee: 35%\t(left_x: 1104   top_y:  479   width:  111   height:  101)\n",
            "Bee: 35%\t(left_x: 1455   top_y:  784   width:   94   height:   92)\n",
            "1600983071.342182\n",
            "1600983071.3619957\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983074.1017988\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 ^C\n",
            "1600983075.4782333\n",
            "1600983075.5013664\n",
            "41\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 ^C\n",
            "1600983077.3216891\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg15.jpg: Predicted in 3.786000 milli-seconds.\n",
            "Bee: 87%\t(left_x:  190   top_y:  652   width:   98   height:  125)\n",
            "Bee: 44%\t(left_x:  538   top_y:  688   width:   95   height:   95)\n",
            "Bee: 45%\t(left_x:  682   top_y:  587   width:   90   height:  106)\n",
            "1600983080.006867\n",
            "1600983080.024015\n",
            "44\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983082.756109\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg12.jpg: Predicted in 3.748000 milli-seconds.\n",
            "Bee: 95%\t(left_x:  189   top_y:  600   width:   96   height:  120)\n",
            "Bee: 48%\t(left_x:  554   top_y:  609   width:  117   height:  150)\n",
            "Bee: 87%\t(left_x: 1214   top_y:  610   width:   99   height:  120)\n",
            "1600983085.5937586\n",
            "1600983085.6139522\n",
            "47\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983088.4035287\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_bee_yolo_fastest_weights/yolo-fastest_training_final.weights...\n",
            " seen 64, trained: 128 K-images (2 Kilo-batches_64) \n",
            "Done! Loaded 126 layers from weights-file \n",
            " Detection layer: 115 - type = 28 \n",
            " Detection layer: 125 - type = 28 \n",
            "/mydrive/yolov3/2_in_1_img/testimg14.jpg: Predicted in 3.864000 milli-seconds.\n",
            "Bee: 34%\t(left_x:  222   top_y:  638   width:   82   height:  122)\n",
            "Bee: 30%\t(left_x:  543   top_y:  689   width:  101   height:   84)\n",
            "Bee: 62%\t(left_x:  670   top_y:  578   width:   82   height:  113)\n",
            "Bee: 68%\t(left_x: 1284   top_y:  704   width:  100   height:  123)\n",
            "1600983091.0963197\n",
            "1600983091.1148953\n",
            "51\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv      8       3 x 3/ 2    320 x 320 x   3 ->  160 x 160 x   8 0.011 BF\n",
            "   1 conv      8       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.003 BF\n",
            "   2 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   3 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   4 conv      8       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x   8 0.002 BF\n",
            "   5 conv      8/   8  3 x 3/ 1    160 x 160 x   8 ->  160 x 160 x   8 0.004 BF\n",
            "   6 conv      4       1 x 1/ 1    160 x 160 x   8 ->  160 x 160 x   4 0.002 BF\n",
            "   7 dropout    p = 0.150        102400  ->   102400\n",
            "   8 Shortcut Layer: 3,  wt = 0, wn = 0, outputs: 160 x 160 x   4 0.000 BF\n",
            "   9 conv     24       1 x 1/ 1    160 x 160 x   4 ->  160 x 160 x  24 0.005 BF\n",
            "  10 conv     24/  24  3 x 3/ 2    160 x 160 x  24 ->   80 x  80 x  24 0.003 BF\n",
            "  11 conv      8       1 x 1/ 1     80 x  80 x  24 ->   80 x  80 x   8 0.002 BF\n",
            "  12 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  13 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  14 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  15 dropout    p = 0.150        51200  ->   51200\n",
            "  16 Shortcut Layer: 11,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  17 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  18 conv     32/  32  3 x 3/ 1     80 x  80 x  32 ->   80 x  80 x  32 0.004 BF\n",
            "  19 conv      8       1 x 1/ 1     80 x  80 x  32 ->   80 x  80 x   8 0.003 BF\n",
            "  20 dropout    p = 0.150        51200  ->   51200\n",
            "  21 Shortcut Layer: 16,  wt = 0, wn = 0, outputs:  80 x  80 x   8 0.000 BF\n",
            "  22 conv     32       1 x 1/ 1     80 x  80 x   8 ->   80 x  80 x  32 0.003 BF\n",
            "  23 conv     32/  32  3 x 3/ 2     80 x  80 x  32 ->   40 x  40 x  32 0.001 BF\n",
            "  24 conv      8       1 x 1/ 1     40 x  40 x  32 ->   40 x  40 x   8 0.001 BF\n",
            "  25 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  26 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  27 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  28 dropout    p = 0.150        12800  ->   12800\n",
            "  29 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  30 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  31 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  32 conv      8       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x   8 0.001 BF\n",
            "  33 dropout    p = 0.150        12800  ->   12800\n",
            "  34 Shortcut Layer: 29,  wt = 0, wn = 0, outputs:  40 x  40 x   8 0.000 BF\n",
            "  35 conv     48       1 x 1/ 1     40 x  40 x   8 ->   40 x  40 x  48 0.001 BF\n",
            "  36 conv     48/  48  3 x 3/ 1     40 x  40 x  48 ->   40 x  40 x  48 0.001 BF\n",
            "  37 conv     16       1 x 1/ 1     40 x  40 x  48 ->   40 x  40 x  16 0.002 BF\n",
            "  38 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  39 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  40 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  41 dropout    p = 0.150        25600  ->   25600\n",
            "  42 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  43 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  44 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  45 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  46 dropout    p = 0.150        25600  ->   25600\n",
            "  47 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  48 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  49 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  50 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  51 dropout    p = 0.150        25600  ->   25600\n",
            "  52 Shortcut Layer: 47,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  53 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  54 conv     96/  96  3 x 3/ 1     40 x  40 x  96 ->   40 x  40 x  96 0.003 BF\n",
            "  55 conv     16       1 x 1/ 1     40 x  40 x  96 ->   40 x  40 x  16 0.005 BF\n",
            "  56 dropout    p = 0.150        25600  ->   25600\n",
            "  57 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  40 x  40 x  16 0.000 BF\n",
            "  58 conv     96       1 x 1/ 1     40 x  40 x  16 ->   40 x  40 x  96 0.005 BF\n",
            "  59 conv     96/  96  3 x 3/ 2     40 x  40 x  96 ->   20 x  20 x  96 0.001 BF\n",
            "  60 conv     24       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  24 0.002 BF\n",
            "  61 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  62 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  63 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  64 dropout    p = 0.150        9600  ->   9600\n",
            "  65 Shortcut Layer: 60,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  66 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  67 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  68 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  69 dropout    p = 0.150        9600  ->   9600\n",
            "  70 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  71 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  72 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  73 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  74 dropout    p = 0.150        9600  ->   9600\n",
            "  75 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  76 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  77 conv    136/ 136  3 x 3/ 1     20 x  20 x 136 ->   20 x  20 x 136 0.001 BF\n",
            "  78 conv     24       1 x 1/ 1     20 x  20 x 136 ->   20 x  20 x  24 0.003 BF\n",
            "  79 dropout    p = 0.150        9600  ->   9600\n",
            "  80 Shortcut Layer: 75,  wt = 0, wn = 0, outputs:  20 x  20 x  24 0.000 BF\n",
            "  81 conv    136       1 x 1/ 1     20 x  20 x  24 ->   20 x  20 x 136 0.003 BF\n",
            "  82 conv    136/ 136  3 x 3/ 2     20 x  20 x 136 ->   10 x  10 x 136 0.000 BF\n",
            "  83 conv     48       1 x 1/ 1     10 x  10 x 136 ->   10 x  10 x  48 0.001 BF\n",
            "  84 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  85 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  86 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  87 dropout    p = 0.150        4800  ->   4800\n",
            "  88 Shortcut Layer: 83,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  89 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  90 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  91 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  92 dropout    p = 0.150        4800  ->   4800\n",
            "  93 Shortcut Layer: 88,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  94 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            "  95 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            "  96 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            "  97 dropout    p = 0.150        4800  ->   4800\n",
            "  98 Shortcut Layer: 93,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            "  99 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 100 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 101 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 102 dropout    p = 0.150        4800  ->   4800\n",
            " 103 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 104 conv    224       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x 224 0.002 BF\n",
            " 105 conv    224/ 224  3 x 3/ 1     10 x  10 x 224 ->   10 x  10 x 224 0.000 BF\n",
            " 106 conv     48       1 x 1/ 1     10 x  10 x 224 ->   10 x  10 x  48 0.002 BF\n",
            " 107 dropout    p = 0.150        4800  ->   4800\n",
            " 108 Shortcut Layer: 103,  wt = 0, wn = 0, outputs:  10 x  10 x  48 0.000 BF\n",
            " 109 conv     96       1 x 1/ 1     10 x  10 x  48 ->   10 x  10 x  96 0.001 BF\n",
            " 110 conv     96/  96  5 x 5/ 1     10 x  10 x  96 ->   10 x  10 x  96 0.000 BF\n",
            " 111 conv    128       1 x 1/ 1     10 x  10 x  96 ->   10 x  10 x 128 0.002 BF\n",
            " 112 conv    128/ 128  5 x 5/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.001 BF\n",
            " 113 conv    128       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x 128 0.003 BF\n",
            " 114 conv     18       1 x 1/ 1     10 x  10 x 128 ->   10 x  10 x  18 0.000 BF\n",
            " 115 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            " 116 route  109 \t\t                           ->   10 x  10 x  96 \n",
            " 117 upsample                 2x    10 x  10 x  96 ->   20 x  20 x  96\n",
            " 118 route  117 81 \t                           ->   20 x  20 x 232 \n",
            " 119 conv     96       1 x 1/ 1     20 x  20 x 232 ->   20 x  20 x  96 0.018 BF\n",
            " 120 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 121 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 122 conv     96/  96  5 x 5/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.002 BF\n",
            " 123 conv     96       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  96 0.007 BF\n",
            " 124 conv     18       1 x 1/ 1     20 x  20 x  96 ->   20 x  20 x  18 0.001 BF\n",
            " 125 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 0.232 \n",
            "avg_outputs = 63714 \n",
            " Allocate additional workspace_size = 2.20 MB \n",
            "Loading weights from /mydrive/yolov3/backup/one_class_pollen_yolo_fastest_weights/yolo-fastest_training_final.weights...Done! Loaded 126 layers from weights-file \n",
            "1600983093.8610504\n",
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n",
            " CUDNN_HALF=1 \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3syovOK9QQIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE66saqLTq3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/darknet/result_bee.json') as f:\n",
        "  data = json.load(f)\n",
        "data = data[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIk9QkL5arIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from extract import json_extract\n",
        "\n",
        "# Find every instance of `name` in a Python dictionary.\n",
        "center_x = json_extract(data, 'center_x')\n",
        "center_y = json_extract(data, 'center_y')\n",
        "width = json_extract(data, 'width')\n",
        "height = json_extract(data, 'height')\n",
        "confidence = json_extract(data, 'confidence')\n",
        "bee_arr = np.column_stack([center_x, center_y, width, height, confidence])\n",
        "\n",
        "print(bee_arr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyRBkcz-lXf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "b908bf29-1c5b-4150-eae1-236e1c39ce85"
      },
      "source": [
        "# The most recent detections are always saved to 'predictions.jpg'\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6b1b2dc7f665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The most recent detections are always saved to 'predictions.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimShow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-3c9f85d6f062>\u001b[0m in \u001b[0;36mimShow\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mresized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9bJCkCy9q4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# detect in a video\n",
        "#videoPath = \"/mydrive/yolov3/Cheng_1.mp4\"\n",
        "#outPath=\"results.avi\"\n",
        "#!./darknet detector demo $objPath $configPath $beeweightsPath -dont_show $videoPath #-i 0 -out_filename $outPath\n",
        "# !./darknet detector test $objPath $configPath $weightsPath data/obj/images/img00470.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DtH4lMS9q2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download the video with detections shown\n",
        "#download(outPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECoK7oAr6ssY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create objPollen.names and objPollen.data for step 2 detection\n",
        "!echo -e 'Pollen' > data/objPollen.names\n",
        "!echo -e 'classes= 1\\ntrain  = data/train.txt\\nvalid  = data/test.txt\\nnames = data/objPollen.names\\nbackup = /mydrive/yolov3' > data/objPollen.data\n",
        "objPollenPath=\"data/objPollen.data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rHAgNggqDEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#val_img_list=\"data/test.txt\"\n",
        "#!cat $val_img_list | wc -l\n",
        "\n",
        "\n",
        "img_list=glob.glob(\"/mydrive/yolov3/2_in_1_img/bee_chips/*.jpg\")\n",
        "#print(img_list)\n",
        "\n",
        "with open(\"data/pollen.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(img_list))\n",
        "val_img_list=\"data/pollen.txt\"\n",
        "!cat $val_img_list | wc -l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7HGjBa89qzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multiple Images at Once\n",
        "\n",
        "!./darknet detector test $objPollenPath $configPath $pollenweightsPath -ext_output -dont_show -out result_pollen.json <$val_img_list> result_pollen.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY2KAP0R-XfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C28NPMi4r4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./darknet detector test $objPollenPath $configPath $pollenweightsPath /mydrive/yolov3/2_in_1_img/bee_chips/bee1.jpg -ext_output -dont_show -out result_pollen.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jawq_q9arXky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download('result.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99JQr5N89quD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download('result.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8ygD_xh9qsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbryO_Nh9qoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp results.avi /mydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnjuFVAP9qlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show mp4 online (don't work yet. it may due to the large size of the mp4)\n",
        "!pip install -U kora\n",
        "from kora.drive import upload_public\n",
        "url = upload_public('/mydrive/results.avi')\n",
        "from IPython.display import HTML\n",
        "HTML(f\"\"\"<video src={url} width=500 controls/>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43x4LN_oykWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert avi to mp4\n",
        "!ffmpeg -i '/mydrive/results.avi' '/mydrive/results.mp4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9W3lmiP9qdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show mp4 online (don't work yet. it may due to the large size of the mp4)\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/mydrive/results.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRxLfLoH9qZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3vjwC-QX-x_",
        "colab_type": "text"
      },
      "source": [
        "Get mAP result from test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV3tDmbKYpu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./darknet detector map data/obj.data cfg/yolo-fastest_training.cfg /mydrive/yolov3/yolo-fastest_training_last.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOmnv9hMYzYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}